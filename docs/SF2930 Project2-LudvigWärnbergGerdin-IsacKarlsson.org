#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage[margin=1.25in]{geometry} \usepackage{booktabs} \usepackage{graphicx} \usepackage{adjustbox} \usepackage{amsmath} \usepackage{amsthm} \newtheorem{definition}{Definition} \usepackage{bookmark}
\begin{titlepage}
\centering
\includegraphics[width=0.15\textwidth]{example-image-1x1}\par\vspace{1cm}
{\scshape\LARGE Kungliga Tekniska Högskolan \par}
\vspace{1cm}
{\scshape\Large SF2930 Regression Analysis \par}
\vspace{1.5cm}
{\huge\bfseries Report II \\  \par}
\vspace{2cm}
{\Large\itshape Isac Karlsson \\ Ludvig Wärnberg Gerdin}
\vfill
Examiner \par
\textsc{Tatjana Pavlenko}

\vfill

{\large \today\par}
\end{titlepage}
# Page break
\newpage
\tableofcontents
\newpage

* Introduction
** Background
  Most of the tractors in Sweden have a third party liability insurance, because they are required by law. 
  In southern Europe a few large players have dominated the sales of tractor insurances. Our main task this
  project is to create our own tractor tariff on the form:
  
  #+NAME: eq:1
  \begin{equation}
    \text{Price} = \gamma_0 \prod_{k = 1}^M \gamma_{k,i}	
  \end{equation}

  Here \gamma_0 corresponds to the base level and $\gamma_{k,i}$ are the risk factors and corresponds to 
  each individual tractor. 

** Data

   If P&C have provided us with data to train this price model, example given in the table below.

** Problem description
*** Risk Differentiation and Grouping

    Using GLM analysis we aim to make each group “Risk homogeneous” and that they contain enough data to
    get a stable GLM analysis, meanwhile handling imperfections in the dataset.

*** Levelling

    Here we aim to calculate yo such that the forecasted claim costs for each insurance are covered by the
    the price for each insurance, on a full year basis. We us a ratio between the estimated claim cost and
    the total premium of 90%. Lastly we calculate the base level yo from the formula given in (1).

* Methods and Methodological Considerations
** Grouping and Risk Differentiation

   The criteria on which we based our grouping was

   1) Each group should be risk homogeneous, and
   2) Each group should have enough data to make the GLM estimates stable.
   Greater emphasis were placed on fulfilling criteria 2) due to it being more concrete. In order to do that
   we choose cut-offs that placed a fairly equal shares of data in each risk group. 

   In addition to the above, we adjusted the data slightly to adjust for some odd rows. For example, 
   the tractors with a weight of 0 were placed in a category of its own. Also, we noticed the use 
   of (Other) and Other as different factor levels for the ActivityCode regressor. These levels, however,
   were left as they are. The rationale was that we assume a tractor with ActivityCode = Other and
   ActivityCode = (Other) are mapped to more specific types of businesses internally by If. In a future version
   of this model, the model could input more granular groups of ActivityCode to potentially improve 
   the performance of the model.

   The resulting cut-offs and risk groups are found in section [[Results]].
   
** Levelling
   
   From the results of section [[Grouping and Risk Differentiation]], we get risk factor estimates for each
   level of each predictor. These are henceforth referred to as the "group factors".
   
   For each corresponding sub-assignment presented under Levelling in the project description, we conducted the
   following:

   1. From the original data, we selected those rows (or tractors) that had a \texttt{RiskYear} 2016. That 
      way the GLM analysis were only conducted on the active customers, leaving out those that weren't 
      customers to If in 2016.

      Following the GLM-script each row were aggregated to include one row per combination of variables. 
      From the aggregated data, we calculated the expected yearly claim-cost per tractor by dividing the
      claim cost by the duration for each row. The rationale for this was to enable us to analyse the 
      yearly cost, even if the insurances had not been active for all of 2016.

      The estimated claim for the coming year is then simply the sum of all of the estimated claim costs 
      for each row in the aggregated data.

   2. Recall that If has a ratio target of 0.9 between the estimated claim cost and the total premium, that is

      #+NAME: eq:2
      \begin{equation}
      \frac{\text{Total expected claim cost}}{\text{Total premiums}} = \frac{E[C_T]}{P_T} = 0.9 
      \end{equation}

      We have equation [[eq:1]] Using that we have an estimated value for the total expected claim cost, we reorder the equation to get
      
      \[
      \frac{E[C_T]}{P_T} = 0.9 \iff \frac{E[C_T]}{0.9} = P_T
      \]

   3. Row by row in the aggregated data, we map the row characteristics to the corresponding risk factor 
      in the group factor table, and subsequently take the product of all the risk factors 
      to obtain the total risk factor for that row. In order to find the base level $\gamma_0$ in

* Results
** Grouping and Risk Differentiation
** Levelling

  \input{../performance_table.tex}

  \input{../risk_groups.tex}

* Conclusion
* Appendix A
